# https://www.digitalocean.com/community/tutorials/how-to-use-ansible-to-install-and-set-up-docker-on-ubuntu-22-04
- name: Deply trino
  hosts: servers # Which host to apply, you can replace by `servers`, or by `servers_1, servers_2` for multiple groups
  become: yes # To run commands as a superuser (e.g., sudo)
  vars:
    default_container_name: datalake-minio
    default_container_image: minio/minio
  tasks:
    - name: Install aptitude
      apt:
        name: aptitude
        state: latest
        update_cache: true

    - name: Install prerequisites
      apt:
        pkg:
          - apt-transport-https
          - ca-certificates
          - curl
          - software-properties-common
          - python3-pip
          - virtualenv
          - python3-setuptools
          - vim
          - openjdk-11-jre-headless
        state: latest
        update_cache: true
    
    # - name: map python3 to python
    #   command: ln -s /usr/bin/python3 /usr/bin/python

    - name: Add Docker GPG apt Key
      apt_key:
        url: https://download.docker.com/linux/ubuntu/gpg
        state: present

    - name: Add Docker Repository
      apt_repository:
        repo: deb https://download.docker.com/linux/ubuntu focal stable
        state: present

    # - name: Update apt and install docker-ce
    #   apt:
    #     name: docker-ce
    #     state: latest
    #     update_cache: true

    - name: Update apt and install docker-ce
      pip:
        name: docker
        version: 6.1.3

    - name: Pull the Docker image
      community.docker.docker_image:
        name: "{{ default_container_image }}"
        source: pull

    - name: Copy trino config to server
      synchronize:
        src: trino
        dest: /home/dunghoang300699
        recursive: yes
        archive: yes
        delete: yes
        compress: yes
      become: yes
    
    - name: Copy datastream_api.py to server
      copy:
        src: ../../gcp/flink/datastream_api.py
        dest: /home/dunghoang300699
        mode: preserve
    
    - name: Copy pyspark_processing.py to server
      copy:
        src: ../../gcp/spark/pyspark_processing.py
        dest: /home/dunghoang300699
        mode: preserve

    - name: Copy diabetes-deltalake data folder to server
      synchronize:
        src: ../../data/diabetes-deltalake
        dest: /home/dunghoang300699
        recursive: yes
        archive: yes
        delete: yes
        compress: yes
      become: yes

    - name: Copy Flink dependencies to server
      synchronize:
        src: ../../jar-files/data_ingestion
        dest: /home/dunghoang300699
        recursive: yes
        archive: yes
        delete: yes
        compress: yes
      become: yes
    
    - name: Copy Spark dependencies to server
      synchronize:
        src: ../../jar-files/jars
        dest: /home/dunghoang300699
        recursive: yes
        archive: yes
        delete: yes
        compress: yes
      become: yes
    
    - name: Copy docker compose file to server
      copy:
        src: docker-compose.yml
        dest: /home/dunghoang300699
        mode: preserve

    - name: Copy airflow docker compose file to server
      copy:
        src: airflow-docker-compose.yaml
        dest: /home/dunghoang300699
        mode: preserve
    
    - name: Copy .env file to server
      copy:
        src: ../../.env
        dest: /home/dunghoang300699
        mode: preserve

    - name: Install Docker Compose
      pip:
        name: docker-compose
        state: present
    
    - name: Copy run_env folder to server
      synchronize:
        src: ../../run_env
        dest: /home/dunghoang300699
        recursive: yes
        archive: yes
        delete: yes
        compress: yes
      become: yes
    
    - name: Copy Dockerfile to server
      copy:
        src: Dockerfile
        dest: /home/dunghoang300699
        mode: preserve

    # https://docs.ansible.com/ansible/latest/collections/community/docker/docker_container_module.html
    - name: Start Docker containers
      community.docker.docker_compose:
        project_src: /home/dunghoang300699
        files: docker-compose.yml
    
    - name: Start airflow containers
      community.docker.docker_compose:
        project_src: /home/dunghoang300699
        files: airflow-docker-compose.yaml

    - name: Install multiple packages
      ansible.builtin.pip:
        name: 
          - pandas 
          - pyspark
