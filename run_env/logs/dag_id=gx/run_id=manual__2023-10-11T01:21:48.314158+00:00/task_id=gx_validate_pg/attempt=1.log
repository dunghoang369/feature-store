[2023-10-11T01:21:53.785+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: gx.gx_validate_pg manual__2023-10-11T01:21:48.314158+00:00 [queued]>
[2023-10-11T01:21:53.791+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: gx.gx_validate_pg manual__2023-10-11T01:21:48.314158+00:00 [queued]>
[2023-10-11T01:21:53.791+0000] {taskinstance.py:1359} INFO - Starting attempt 1 of 1
[2023-10-11T01:21:53.798+0000] {taskinstance.py:1380} INFO - Executing <Task(GreatExpectationsOperator): gx_validate_pg> on 2023-10-11 01:21:48.314158+00:00
[2023-10-11T01:21:53.806+0000] {standard_task_runner.py:57} INFO - Started process 152 to run task
[2023-10-11T01:21:53.808+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'gx', 'gx_validate_pg', 'manual__2023-10-11T01:21:48.314158+00:00', '--job-id', '1381', '--raw', '--subdir', 'DAGS_FOLDER/gx.py', '--cfg-path', '/tmp/tmplc86rds8']
[2023-10-11T01:21:53.809+0000] {standard_task_runner.py:85} INFO - Job 1381: Subtask gx_validate_pg
[2023-10-11T01:21:53.834+0000] {task_command.py:415} INFO - Running <TaskInstance: gx.gx_validate_pg manual__2023-10-11T01:21:48.314158+00:00 [running]> on host 08721473190e
[2023-10-11T01:21:53.872+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='gx' AIRFLOW_CTX_TASK_ID='gx_validate_pg' AIRFLOW_CTX_EXECUTION_DATE='2023-10-11T01:21:48.314158+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2023-10-11T01:21:48.314158+00:00'
[2023-10-11T01:21:53.872+0000] {great_expectations.py:551} INFO - Running validation with Great Expectations...
[2023-10-11T01:21:53.872+0000] {great_expectations.py:553} INFO - Instantiating Data Context...
[2023-10-11T01:21:53.876+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2023-10-11T01:21:53.891+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.8/site-packages/great_expectations/data_context/data_context/base_data_context.py:158: DeprecationWarning: DataContext and BaseDataContext are deprecated as of v0.17.10 and will be removed in v0.20. Please use gx.get_context instead.
  warnings.warn(

[2023-10-11T01:21:53.898+0000] {file_data_context.py:224} INFO - FileDataContext loading fluent config
[2023-10-11T01:21:53.900+0000] {config.py:185} INFO - Loading 'datasources' ->
[]
[2023-10-11T01:21:53.903+0000] {abstract_data_context.py:1295} INFO - Profiler store is not configured; omitting it from active stores
[2023-10-11T01:21:53.906+0000] {abstract_data_context.py:1295} INFO - Profiler store is not configured; omitting it from active stores
[2023-10-11T01:21:53.907+0000] {abstract_data_context.py:1295} INFO - Profiler store is not configured; omitting it from active stores
[2023-10-11T01:21:53.909+0000] {abstract_data_context.py:1295} INFO - Profiler store is not configured; omitting it from active stores
[2023-10-11T01:21:53.910+0000] {abstract_data_context.py:1295} INFO - Profiler store is not configured; omitting it from active stores
[2023-10-11T01:21:53.937+0000] {great_expectations.py:566} INFO - Creating Checkpoint...
[2023-10-11T01:21:53.938+0000] {great_expectations.py:585} INFO - Running Checkpoint...
[2023-10-11T01:21:53.951+0000] {taskinstance.py:1935} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "***.strawberries" does not exist
LINE 2: FROM ***.strawberries 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/great_expectations_provider/operators/great_expectations.py", line 588, in execute
    result = self.checkpoint.run(batch_request=self.batch_request)
  File "/home/airflow/.local/lib/python3.8/site-packages/great_expectations/core/usage_statistics/usage_statistics.py", line 260, in usage_statistics_wrapped_method
    result = func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/great_expectations/checkpoint/checkpoint.py", line 315, in run
    self._run_validation(
  File "/home/airflow/.local/lib/python3.8/site-packages/great_expectations/checkpoint/checkpoint.py", line 480, in _run_validation
    validator: Validator = self._validator or self.data_context.get_validator(
  File "/home/airflow/.local/lib/python3.8/site-packages/great_expectations/data_context/data_context/abstract_data_context.py", line 2482, in get_validator
    self.get_batch_list(
  File "/home/airflow/.local/lib/python3.8/site-packages/great_expectations/core/usage_statistics/usage_statistics.py", line 260, in usage_statistics_wrapped_method
    result = func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/great_expectations/data_context/data_context/abstract_data_context.py", line 2651, in get_batch_list
    return self._get_batch_list(
  File "/home/airflow/.local/lib/python3.8/site-packages/great_expectations/data_context/data_context/abstract_data_context.py", line 2732, in _get_batch_list
    return datasource.get_batch_list_from_batch_request(batch_request=result)
  File "/home/airflow/.local/lib/python3.8/site-packages/great_expectations/datasource/new_datasource.py", line 218, in get_batch_list_from_batch_request
    ) = data_connector.get_batch_data_and_metadata(
  File "/home/airflow/.local/lib/python3.8/site-packages/great_expectations/datasource/data_connector/data_connector.py", line 121, in get_batch_data_and_metadata
    batch_data, batch_markers = self._execution_engine.get_batch_data_and_markers(
  File "/home/airflow/.local/lib/python3.8/site-packages/great_expectations/execution_engine/sqlalchemy_execution_engine.py", line 1388, in get_batch_data_and_markers
    batch_data = SqlAlchemyBatchData(
  File "/home/airflow/.local/lib/python3.8/site-packages/great_expectations/execution_engine/sqlalchemy_batch_data.py", line 181, in __init__
    self._selectable = self._generate_selectable_from_selectable(
  File "/home/airflow/.local/lib/python3.8/site-packages/great_expectations/execution_engine/sqlalchemy_batch_data.py", line 417, in _generate_selectable_from_selectable
    _, temp_table_name = self._create_temporary_table(
  File "/home/airflow/.local/lib/python3.8/site-packages/great_expectations/execution_engine/sqlalchemy_batch_data.py", line 311, in _create_temporary_table
    self.execution_engine.execute_query_in_transaction(sa.text(stmt))
  File "/home/airflow/.local/lib/python3.8/site-packages/great_expectations/execution_engine/sqlalchemy_execution_engine.py", line 1478, in execute_query_in_transaction
    result = connection.execute(query)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1385, in execute
    return meth(self, multiparams, params, _EMPTY_EXECUTION_OPTS)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "***.strawberries" does not exist
LINE 2: FROM ***.strawberries 
             ^

[SQL: CREATE TEMPORARY TABLE "gx_temp_c3b0d294" AS SELECT * 
FROM k6.strawberries 
WHERE true]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2023-10-11T01:21:53.964+0000] {taskinstance.py:1398} INFO - Marking task as FAILED. dag_id=gx, task_id=gx_validate_pg, execution_date=20231011T012148, start_date=20231011T012153, end_date=20231011T012153
[2023-10-11T01:21:53.971+0000] {standard_task_runner.py:104} ERROR - Failed to execute job 1381 for task gx_validate_pg ((psycopg2.errors.UndefinedTable) relation "***.strawberries" does not exist
LINE 2: FROM ***.strawberries 
             ^

[SQL: CREATE TEMPORARY TABLE "gx_temp_c3b0d294" AS SELECT * 
FROM k6.strawberries 
WHERE true]
(Background on this error at: https://sqlalche.me/e/14/f405); 152)
[2023-10-11T01:21:54.019+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 1
[2023-10-11T01:21:54.035+0000] {taskinstance.py:2776} INFO - 0 downstream tasks scheduled from follow-on schedule check
